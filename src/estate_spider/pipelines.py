# src/estate_spider/pipelines.py
import re
import pymysql

class DataCleaningPipeline:
    def process_item(self, item, spider):
        # --- 1. æ¸…æ´—æ€»ä»· ---
        try:
            # åŸå§‹: " 258 " -> æ¸…æ´—å: 258.0
            raw_total = item.get('total_price', '')
            item['price_total'] = float(raw_total.strip())
        except:
            item['price_total'] = 0.0

        # --- 2. æ¸…æ´—å•ä»· ---
        try:
            # åŸå§‹: "29,888å…ƒ/å¹³" -> æ¸…æ´—å: 29888.0
            raw_unit = item.get('unit_price', '')
            # å»æ‰é€—å·ã€å•ä½
            clean_unit = raw_unit.replace(',', '').replace('å…ƒ/å¹³', '').strip()
            item['price_unit'] = float(clean_unit)
        except:
            item['price_unit'] = 0.0

        # --- 3. æ·±åº¦æ‹†è§£ house_info ---
        # åŸå§‹: "3å®¤2å… | 89.5å¹³ç±³ | å— | ç²¾è£…"
        raw_info = item.get('house_info', '')
        
        # é»˜è®¤å€¼
        item['rooms'] = 0
        item['halls'] = 0
        item['area'] = 0.0
        item['orientation'] = "æœªçŸ¥"

        if raw_info:
            parts = [p.strip() for p in raw_info.split('|')]
            
            # A. æå–æˆ·å‹ (æ­£åˆ™æ‰¾ "Xå®¤Yå…")
            room_match = re.search(r'(\d+)å®¤(\d+)å…', raw_info)
            if room_match:
                item['rooms'] = int(room_match.group(1))
                item['halls'] = int(room_match.group(2))
            
            # B. æå–é¢ç§¯ (æ‰¾å¸¦ "å¹³ç±³" çš„éƒ¨åˆ†)
            for p in parts:
                if 'å¹³ç±³' in p:
                    try:
                        area_str = p.replace('å¹³ç±³', '').strip()
                        item['area'] = float(area_str)
                    except:
                        pass
                    break
            
            # C. æå–æœå‘ (é€šå¸¸åœ¨ç¬¬3ä½ï¼Œä½†ä¹Ÿå¯èƒ½å˜åŠ¨ï¼Œè¿™é‡Œç®€å•å–ç¬¬3æ®µ)
            if len(parts) >= 3:
                # æ’é™¤æ‰åŒ…å«æ•°å­—çš„æ®µï¼ˆé˜²æ­¢æŠŠæ¥¼å±‚å½“æœå‘ï¼‰
                if not any(char.isdigit() for char in parts[2]):
                    item['orientation'] = parts[2]

        # --- 4. æ§åˆ¶å°å¯è§†åŒ–æ‰“å° (Debugä¸“ç”¨) ---
        print("-" * 60)
        print(f"ğŸ  å°åŒº: {item['community']}")
        print(f"ğŸ“„ åŸå§‹ä¿¡æ¯: {raw_info}")
        print(f"âœ¨ æ¸…æ´—ç»“æœ: {item['rooms']}å®¤ {item['halls']}å… | {item['area']}å¹³ | æœå‘:{item['orientation']}")
        print(f"ğŸ’° ä»·æ ¼æ¸…æ´—: æ€»ä»·[{item['price_total']}ä¸‡]  å•ä»·[{item['price_unit']}å…ƒ/å¹³]")
        print("-" * 60)

        return item
    
class MysqlPipeline:
    """
    è´Ÿè´£å°†æ¸…æ´—åçš„ç»“æ„åŒ–æ•°æ®å­˜å…¥ MySQL æ•°æ®åº“
    """
    # 1. åˆå§‹åŒ–æ–¹æ³•ï¼šä» settings.py è¯»å–é…ç½®
    def __init__(self, host, user, password, db, port):
        self.host = host
        self.user = user
        self.password = password
        self.db = db
        self.port = port
        
        # ç¡®ä¿åœ¨è¿è¡Œå‰å®‰è£…äº† pymysql
        if 'pymysql' not in globals():
            raise ImportError("è¯·å…ˆå®‰è£… pymysql: pip install pymysql")

    @classmethod
    def from_crawler(cls, crawler):
        return cls(
            host=crawler.settings.get('MYSQL_HOST'),
            user=crawler.settings.get('MYSQL_USER'),
            password=crawler.settings.get('MYSQL_PASSWORD'),
            db=crawler.settings.get('MYSQL_DB'),
            port=crawler.settings.get('MYSQL_PORT'),
        )

    # 2. çˆ¬è™«å¯åŠ¨æ—¶ï¼šè¿æ¥æ•°æ®åº“å¹¶åˆ›å»ºè¡¨
    def open_spider(self, spider):
        self.conn = pymysql.connect(
            host=self.host,
            user=self.user,
            password=self.password,
            database=self.db,
            port=self.port,
            charset='utf8mb4'
        )
        self.cursor = self.conn.cursor()
        
        # æ ¸å¿ƒï¼šå»ºè¡¨è¯­å¥ï¼Œå­—æ®µå¿…é¡»ä¸æ¸…æ´—åçš„ Item å¯¹åº”
        create_table_sql = """
        CREATE TABLE IF NOT EXISTS beike_house (
            id INT AUTO_INCREMENT PRIMARY KEY,
            title VARCHAR(255),
            community VARCHAR(100),
            region VARCHAR(100),
            
            rooms INT DEFAULT 0,
            halls INT DEFAULT 0,
            area FLOAT DEFAULT 0,
            orientation VARCHAR(50),
            price_total FLOAT DEFAULT 0,
            price_unit FLOAT DEFAULT 0,
            
            detail_url VARCHAR(255) UNIQUE,
            crawled_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
        """
        self.cursor.execute(create_table_sql)
        self.conn.commit()
        print("âœ… [Pipeline] MySQL è¿æ¥æˆåŠŸä¸”è¡¨å·²å°±ç»ªï¼")

    # 3. çˆ¬è™«å…³é—­æ—¶ï¼šæ–­å¼€è¿æ¥
    def close_spider(self, spider):
        self.conn.close()

    # 4. æ¥æ”¶ Itemï¼šæ‰§è¡Œæ’å…¥æ“ä½œ
    def process_item(self, item, spider):
        # ä½¿ç”¨ INSERT IGNORE é¿å…é‡å¤æ’å…¥ (åŸºäº detail_url çš„ UNIQUE çº¦æŸ)
        sql = """
        INSERT IGNORE INTO beike_house 
        (title, community, region, rooms, halls, area, orientation, price_total, price_unit, detail_url)
        VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
        """
        try:
            self.cursor.execute(sql, (
                item.get('title'),
                item.get('community'),
                item.get('region'),
                item.get('rooms'),
                item.get('halls'),
                item.get('area'),
                item.get('orientation'),
                item.get('price_total'),
                item.get('price_unit'),
                item.get('detail_url')
            ))
            self.conn.commit()
            # è¿™é‡Œçš„æ‰“å°å¯ä»¥åœ¨è°ƒè¯•ç»“æŸååˆ é™¤
            print(f"ğŸ’¾ [MySQL] å·²å­˜å‚¨: {item.get('community')} ({item.get('price_total')}ä¸‡)")
        except Exception as e:
            # å¿½ç•¥é‡å¤æ’å…¥çš„é”™è¯¯ï¼Œåªæ‰“å°å…¶ä»–é”™è¯¯
            if 'Duplicate entry' not in str(e):
                print(f"âŒ [MySQL] æ’å…¥å¤±è´¥: {e}")
            self.conn.rollback()
            
        return item